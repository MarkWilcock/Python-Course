{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Cleaning Data With Pandas\n","\n","In this exercise, we load data from an Excel spreadsheet, clean the dataset, then save the cleaned data to a new Excel sheet.\n","\n","This dataset contains a list of 891 of the passengers on board including variables (columns) such as Name, Age, Sex, and Pclass i.e. whether they travelled 1st, 2nd or 3rd class.  We need to clean the data.  Some variables have missing values.  The names of the variables, are cryptic and so are the values. This file is at a public web location - the URL is provided.  The workbook has several sheets, the passenger data is in a sheet named 'Passengers'.\n","\n","Here are some suggested data quality improvements:\n","* Remove the Ticket and Cabin columns (we don’t need them in this exercise).\n","* split the Name column into three columns: last_name, title and other_names.  \n","* The Survived column has two values 0 and 1 to indicate whether the passenger died or survived.  These values are not intuitive.  Create a new column survival, with values 'Died' or 'Survived' based on the value of the Survived column (0 and 1 respectively).\n","* The Pclass column has values 1, 2 and 3.  Perhaps integer values are not best in this case – is a 2nd class passenger somehow twice as much as a 1st class? Create a new column passenger_class with values '1st', '2nd' and '3rd'.\n","* In the Embarked column, replace S, C and Q values with Southampton, Cherbourg and Queenstown respectively.  Deal with the two empty values.\n","* add a column family_size, with formula = [SibSp]+[Parch]+1\n","* remove any further columns we no longer need e.g. Survived\n","* rename any columns to a more Pythonic style with lowercase and underscore style e.g.PassengerId -> passenger_id \n","\n","### Background\n","Almost everyone knows the story of the Titanic.  In April 1912, this magnificent ship left Southampton on its maiden voyage to New York but it never arrived.  It hit an iceberg in the Atlantic and sank.  There were over 2,000 people on board.  Less than half survived.\n","A century later, this Titanic dataset is a classic case study for rookie data scientist to build a predictive model to determine who is likely to survive or perish (ignoring the fact that this is a matter of historical record). However, we will visualise the data with Power BI and see if we can gain some intuition and who did and did not survive and why.  We know from the film that Kate Winslet survived but poor old Leo DiCaprio did not – is that an accurate reflection?"]},{"cell_type":"markdown","metadata":{},"source":["Note: we may need to pip install pandas, numpy, openpyxl (a dependency of pandas required for opening Excel sheets)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FdDijI4sanGz"},"outputs":[],"source":["import pandas as pd\n","import numpy as np "]},{"cell_type":"markdown","metadata":{},"source":["The Excel file is at this location"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDMCTFx5ach1"},"outputs":[],"source":["file_url = \"https://github.com/MarkWilcock/CourseDatasets/raw/main/Misc%20Datasets/Titanic%20Data.xlsx\""]},{"cell_type":"markdown","metadata":{},"source":["This next code cell loads the data in the Passengers sheet of an Excel file at the file_url into a pandas DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"elapsed":1135,"status":"ok","timestamp":1704893965348,"user":{"displayName":"London Business Analytics Group","userId":"01279057383787913906"},"user_tz":0},"id":"NomjoJWaatV9","outputId":"ed6c9360-d451-4b9f-ae76-4a62958ab5e6"},"outputs":[],"source":["df = pd.read_excel(file_url,sheet_name=\"Passengers\")\n","df.head(2) # Show first 2 rows"]},{"cell_type":"markdown","metadata":{},"source":["Remove the Cabin and Ticket columns.  Use the drop() method of the DataFrame class.\n","This method returns a changed DataFrame but does not by default change the original DataFrame so we have two options\n","* assign the DataFrame as the result i.e., df = df.drop(.....)\n","* use the inplace argument to change the default behaviour"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":634},"executionInfo":{"elapsed":197,"status":"ok","timestamp":1704894098161,"user":{"displayName":"London Business Analytics Group","userId":"01279057383787913906"},"user_tz":0},"id":"I87uVwoqa_VM","outputId":"6e2f8adb-4dad-4c3d-ff29-07046088db71"},"outputs":[],"source":["# Write your code here\n","df.drop(columns=['Cabin', 'Ticket'], inplace=True)\n","df.head(2) # Show first 2 rows"]},{"cell_type":"markdown","metadata":{},"source":["The next code cell shows how to create a new column, passenger_class, with values based on the values in Pclass column.  \n","The values are mapped from Pclass: 1 to 1st, 2 to 2nd, 3 to 3rd.\n","It uses the map function and a dictionary of old and new values.  \n","Finally it drops the Pclass column as it is no longer needed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['passenger_class'] = df['Pclass'].map({1:'1st', 2:'2nd', 3:'3rd'})\n","df.drop(columns='Pclass')\n","df.head(2) # Show first 2 rows"]},{"cell_type":"markdown","metadata":{},"source":["Use the same tehnique to add a column named survival with values based on the values in the Survived column.  \n","Map values of 0 to No, 1 to Yes.  \n","Finally drop the Survived column."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write your code here\n","df['survival'] = df['Survived'].map({0:'Died', 1:'Survived'})\n","df.drop(columns='Survived')\n","df.head(2) # Show first 2 rows"]},{"cell_type":"markdown","metadata":{},"source":["Add a column, family_size, calculated as SibSp + Parch + 1. \n"," \n","Explanation: For each passenger, the family size the sum of:\n","1. the number of parents and children (Parch), \n","1. the number of siblings and spouses (SibSp), \n","1. the passenger themselves\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write your code here\n","df['family_size'] = df['SibSp'] + df['Parch'] + 1\n","df.head(2) # Show first 2 rows"]},{"cell_type":"markdown","metadata":{},"source":["Replace the values of the Embarked column with the full words, C to Cherbourg, Q to Queenstown, S to Southampton.\n","Use either the DataFrame map or replace method"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write your code here\n","df['Embarked'] = df['Embarked'].map({'C':'Cherbourg', 'Q':'Queenstown', 'S':'Southampton'})\n","#df.Embarked = df.Embarked.replace({'C':'Cherbourg1', 'Q':'Queenstown1', 'S':'Southampton1'})\n","df.head(2) # Show first 2 rows"]},{"cell_type":"markdown","metadata":{},"source":["Split the Name column into three columns: last_name, title and other_names.  \n","\n","You may want to use the following arguments and values in the split() function\n","* expand=True: This ensures that the result of the split operation is a DataFrame with separate columns for each split component.\n","* n=1: This limits the split to at most 1 time. So, the string will be split into two parts: everything before the first delimter, and everything after it. This is useful when the  delimiter may appear more than once and we only want the first occurrence to split the string."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write your code here\n","df[['last_name', 'remainder']] = df['Name'].str.split(',', expand=True, n=1)\n","df[['title', 'other_names']] = df['remainder'].str.split('.', expand=True, n=1)\n","df.drop(columns=['remainder', 'Name'], inplace=True)\n","\n","df.head(2) # Show first 2 rows"]},{"cell_type":"markdown","metadata":{},"source":["Empty values of Age, presumably np.nan values in Python, are shown as #NUM! in Excel, so need to replace - an empty string seems best.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.Age"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Age column stats:\\n\", df.Age.describe())\n","\n","print(\"One row in final five rows has missing value for Age:\\n\", df.tail())\n","\n","print(\":\\n\")\n","df.Age.isna()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write your code here\n","df['age'] = df.Age.replace(np.nan, '')\n","df.tail() # the last 5 contain a row with nan values of Age "]},{"cell_type":"markdown","metadata":{},"source":["Remove the columns we no longer need"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write your code here\n","df.drop(columns=['SibSp', 'Parch', 'Pclass', 'Survived', 'Age'], inplace=True)\n","df.head(2) # Show first 2 rows"]},{"cell_type":"markdown","metadata":{},"source":["Rename any columns to a more Pythonic style with lowercase and undercscore style e.g.PassengerId -> passenger_id   \n","Use the DataFrame rename method with a dictionary to map old names (key) to new names (value)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write your code here\n","names_dict = {'PassengerId':'passenger_id', 'Sex': 'sex', 'Fare': 'fare', 'Embarked': 'embarked' }\n","df.rename(columns=names_dict, inplace=True)\n","df.head(2) # Show first 2 rows"]},{"cell_type":"markdown","metadata":{},"source":["Saved this cleaned DataFrame to an Excel file in the local folder. Name this file \"titanic_clean.xlsx\"\n","Use the DataFrame to_excel method"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":455,"status":"ok","timestamp":1704894162312,"user":{"displayName":"London Business Analytics Group","userId":"01279057383787913906"},"user_tz":0},"id":"22HhsKhhcdom"},"outputs":[],"source":["# Write your code here\n","# If we are using Colab, we may need to uncomment the next code cell to save the clean data to a file on your Google drive\n","#from google.colab import drive\n","#drive.mount('/drive')\n","df.to_excel(\"titanic_clean.xlsx\", index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Filtering the dataset"]},{"cell_type":"markdown","metadata":{},"source":["Return a filtered DataFrame of 2nd class passengers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write your code here\n","second_class_passengers = df.loc[df['passenger_class'] == '2nd']\n","second_class_passengers"]},{"cell_type":"markdown","metadata":{},"source":["Return a filtered DataFrame of women who embarked at Cherbourg and travelled 2nd class"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write your code here\n","second_class_women_cherbourg = df[(df['passenger_class'] == '2nd') & (df['sex'] == 'female') & (df['embarked'] == 'Cherbourg')]\n","second_class_women_cherbourg"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMwYMVrNq31AO7h0G3cIEeZ","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
