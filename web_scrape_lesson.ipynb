{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping data from web pages\n",
    "\n",
    "This example scrapes data from a HTML table firstly into a pndas dataframe and then exports to a CSV file.  \n",
    "It uses \n",
    "* [beautifulsoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/), a popular web scraping library; \n",
    "* pandas, the de-facto library for data analysis; \n",
    "* and requests, the most popular Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wikipedia page provides the results for the 20th series of Strictly, a Saturday evening light entertainment dance competition on the BBC. This series started in September 2022.\n",
    "The next code cell gets all the details of the page, including the HTML content, into a variable.\n",
    "Before running the next cell, [view this page](https://en.wikipedia.org/wiki/Strictly_Come_Dancing_(series_20)) in a browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strictly_url = 'https://en.wikipedia.org/wiki/Strictly_Come_Dancing_(series_20)'\n",
    "response = requests.get(strictly_url)\n",
    "response.status_code, response.content[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell uses beautifulsoup to parse the content, and then shows the first 1000 character in a formatted style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "print(soup.prettify()[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HTML page contains a table which is the first HTML table within a span section with the id Week_6:_Halloween_Week.  This table contains the data of interest, the score that couples obtained from the judges for a dance. The next code cell finds and gets the HTML content that reprsents this table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_halloween = soup.find('span', {'id': 'Week_6:_Halloween_Week'})\n",
    "my_table = span_halloween.find_next('table')\n",
    "my_table.prettify()[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell uses the pandas read_html function to read data from the HTML table text into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(str(my_table))[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current column names are a bit ugly. The next code cell renames the columns of the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['couple', 'score','dance','music','result']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell saves the dataframe to a CSV file for later use, perhaps within Power BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('strictly.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
